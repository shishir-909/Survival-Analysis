std.err_Log.quantile_0.1_varSig <- sqrt(Var_Log.quantile_0.1_varSig)
lower_wald95_quantile_0.1_varSig <- exp(log(quantile_0.1_varSig) - (qnorm(0.975)*std.err_Log.quantile_0.1_varSig))
upper_wald95_quantile_0.1_varSig <- exp(log(quantile_0.1_varSig) + (qnorm(0.975)*std.err_Log.quantile_0.1_varSig))
Var_Log.quantile_0.5_varSig <- A + ((z.50**2)*B) + (2*z.50*C)
std.err_Log.quantile_0.5_varSig <- sqrt(Var_Log.quantile_0.5_varSig)
lower_wald95_quantile_0.5_varSig <- exp(log(quantile_0.5_varSig) - (qnorm(0.975)*std.err_Log.quantile_0.5_varSig))
upper_wald95_quantile_0.5_varSig <- exp(log(quantile_0.5_varSig) + (qnorm(0.975)*std.err_Log.quantile_0.5_varSig))
quantile_df <- data.frame(t.p = c(quantiles_0.1_0.5$fit,quantile_0.1_varSig,quantile_0.5_varSig), t.p.se = c(quantiles_0.1_0.5$se.fit,std.err_Log.quantile_0.1_varSig,std.err_Log.quantile_0.5_varSig), wald_lower = c(lower_wald95,lower_wald95_quantile_0.1_varSig,lower_wald95_quantile_0.5_varSig),
wald_upper = c(upper_wald95,upper_wald95_quantile_0.1_varSig,upper_wald95_quantile_0.5_varSig))
View(quantile_df)
quantile_df<- quantile_df %>%
dplyr::mutate(quantile = c("$\\hat{t_{0.1}}$","$\\hat{t_{0.5}}$","$\\hat{t_{0.1}}$","$\\hat{t_{0.5}}$"))
quantile_df<- quantile_df %>%
dplyr::mutate(quantile = c("$\\hat{t_{0.1}}$","$\\hat{t_{0.5}}$","$\\hat{t_{0.1}}$","$\\hat{t_{0.5}}$")) %>%
dplyr::select(quantile, everything())
quantile_df<- quantile_df %>%
dplyr::mutate(quantile = c("$\\hat{t_{0.1}}$","$\\hat{t_{0.5}}$","$\\hat{t_{0.1}}$","$\\hat{t_{0.5}}$")) %>%
dplyr::select(quantile, everything()) %>%
dplyr::mutate(Model = c(rep("Constant Shape",2),rep("Varying Shape",2))) %>%
dplyr::select(Model, everything())
t <- knitr::kable(quantile_df, align = rep('c', 5), table.envir = 'table*', escape = FALSE, digits = 3) %>%
kableExtra::kable_styling("striped", full_width = T, position = "left")
kableExtra::collapse_rows(t)
colnames(quantile_df) <- c("Model","Quantile","ML estimate","Standard Error","Wald Lower 95% CI","Wald Upper 95% CI")
t <- knitr::kable(quantile_df, align = rep('c', 5), table.envir = 'table*', escape = FALSE, digits = 3) %>%
kableExtra::kable_styling("striped", full_width = T, position = "left")
kableExtra::collapse_rows(t)
View(ceramic)
#First, add a column for the linear predictors. This is nothing but "mu + gamma.transpose*Z" for every observation.
ceramic <- ceramic %>%
dplyr::mutate(LinearPredictor = beta.0 + (beta.1*log(Stress)))
#Next, add a column for standardized residuals. The definition of standardized residual for a log-location-scale model is given by Eq 17.12 in SMRD2
ceramic <- ceramic %>%
dplyr::mutate(sigma.i = exp(beta.0s + (beta.1s*log(Stress)))) %>%
dplyr::mutate(stdResid = exp((log(Revolutions)-LinearPredictor)/sigma.i)) %>%
dplyr::mutate(stdResid.round = round(stdResid,3))
ggplot(ceramic, aes(x = exp(LinearPredictor), y = stdResid, group = delta)) + geom_point() + coord_trans(x = 'log', y = 'log') + ylab("Standardized Residuals") + xlab("Fitted Values") #Matches figure 17.5a! Notice that the variability is higher at larger fitted values.
#+ geom_point(aes(shape = factor(delta, levels = c(1,0))))
fitModel1.KaplanMeir <- survival::survfit(Surv(stdResid.round,delta) ~ 1, data = ceramic)
summary(fitModel1.KaplanMeir)
confBands2 <- km.ci::km.ci(fitModel1.KaplanMeir, conf.level = 0.95, method = "logep") #"logep" recommended by km.ci package documentation.
weibullPlot.model1 <- data.frame(t.p = fitModel1.KaplanMeir[["time"]],
survival.p = fitModel1.KaplanMeir[["surv"]]) %>%
dplyr::mutate(p = 1 - survival.p) %>%
dplyr::filter(row_number() <= n()-1) %>% #The observation with survival probability 0 i.e. the last observation is removed since we cannot have confidence band values for this observation.
dplyr::mutate(survival.lower = confBands2$lower,
survival.upper = confBands2$upper) %>%
dplyr::mutate(p.lower = round(1 - survival.upper,3),
p.upper = round(1 - survival.lower,3))
xTransformer <- scales::trans_new(
name = "weibull.x.transform",
transform = function(t.p){
x = log(t.p)
return(x)
},
inverse = function(x) {
t.p = exp(x)
return(t.p)
}
)
yTransfomer <- scales::trans_new(
name = "weibull.y.transform",
transform = function(p){
y = log(-log(1-p))
return(y)
},
inverse = function(y) {
p = 1 - exp(-exp(y))
return(p)
}
)
ggplot(weibullPlot.model1, aes(x = t.p, y = p)) + geom_point() + geom_step(aes(y = p.lower)) + geom_step(aes(y = p.upper)) + scale_x_continuous(transform = xTransformer, name = "Standardized Residuals", breaks = c(0.001,0.01, 0.1, 1)) + scale_y_continuous(transform = yTransfomer, name = "Fraction Failing",breaks = seq(0.01,0.99,0.05))
View(weibullPlot.model1)
weibullPlot.model1$p.upper[c(1)] <- weibullPlot.model1$p.upper[2]
std.resid.prob.plot <- ggplot(weibullPlot.model1, aes(x = t.p, y = p)) + geom_point() + geom_step(aes(y = p.lower)) + geom_step(aes(y = p.upper)) + scale_x_continuous(transform = xTransformer, name = "Standardized Residuals", breaks = c(0.001,0.01, 0.1, 1,2,3)) + scale_y_continuous(transform = yTransfomer, name = "Fraction Failing",breaks = seq(0.01,0.99,0.1))
R <- suppressWarnings(print(std.resid.prob.plot))
fs1 <- flexsurv::flexsurvreg(Surv(Revolutions, delta) ~ log(Stress) + shape(log(Stress)), data = ceramic, dist = "weibull")
fs1
View(fs1)
fs1[["coefficients"]]
fs1[["covdata"]]
fs1[["cov"]]
fs1[["coefficients"]]
fs1[["cov"]]
varcov
predict(fs1,
newdata = data.frame(Stress = 1.15), type = 'quantile', p=c(0.1,0.5), se.fit = T)
fs_quantile <- predict(fs1,
newdata = data.frame(Stress = 1.15), type = 'quantile', p=c(0.1,0.5), se.fit = T)
fs_quantile
View(fs_quantile)
View(fs_quantile[[1]][[1]])
std.err_Log.quantile_0.1_varSig
std.err_quantile_0.1_varSig <- quantile_0.1_varSig*std.err_Log.quantile_0.1_varSig
std.err_quantile_0.1_varSig
std.err_quantile_0.5_varSig <- quantile_0.5_varSig*std.err_Log.quantile_0.5_varSig
std.err_quantile_0.5_varSig
View(fs_quantile)
View(fs_quantile[[1]][[1]])
# Chunk 1: Load Libraries
library(tufte)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
library(survival)
library(tidyverse)
library(readr)
library(survminer)
library(kableExtra)
library(flexsurv)
library(gridExtra)
library(km.ci)
setwd("G:/My Drive/rao@ualberta.ca 2022-12-08 10 58/shishir@tamu.edu/My Drive/Interesting papers/Survival Models/GitHub/Survival/Survival-Analysis/Blog 6")
# Chunk 2: Load Table
ceramic <- read_csv("Data/CeramicBearing02.csv", show_col_types = FALSE)
knitr::kable(ceramic, align = rep('c', 5), table.envir = 'table*') %>%
kableExtra::kable_styling("striped", full_width = T, position = "left") %>%
kableExtra::scroll_box(height = "200px")
#, caption = "Table 1. Ceramic Bearings Life Test Data"
# Chunk 3: Rename Columns
ceramic <- ceramic %>%
dplyr::rename(Revolutions = `Millions of Revolutions`,
Stress = `Stress (Mpsi)`) %>%
dplyr::mutate(delta = rep(1,nrow(ceramic))) #No censored observations
# ceramic <- ceramic %>%
#   dplyr::filter(Revolutions != 0.012)
# Chunk 4: IRLS computations continuous varSig
#My manual notes here: https://drive.google.com/open?id=1-MXUBr5OvIk7O1HKI27Cd-jBnlNdB0E6&usp=drive_fs
ceramic <- ceramic %>%
dplyr::mutate(logStress = log(Stress)) %>%
dplyr::mutate(y = log(Revolutions))
iterest <- function(beta.0, beta.1, beta.0s, beta.1s){
beta.vector <- matrix(c(beta.0, beta.1), nrow = 2)
X.matrix <- matrix(c(rep(1,dim(ceramic)[1]),ceramic$logStress), nrow = dim(ceramic)[1])
n <- nrow(X.matrix)
n.F <- sum(ceramic$delta)
sigma.i <- exp(beta.0s + (beta.1s*ceramic$logStress))
r.i <- (ceramic$y - (X.matrix %*% beta.vector))/sigma.i
ceramic.1 <- ceramic %>%
dplyr::mutate(r.i = r.i,
sigma.i = sigma.i) %>%
dplyr::mutate(u = case_when(delta == 1 ~ ((-1/sigma.i)*(1-exp(r.i))),
delta == 0 ~ ((1/sigma.i)*exp(r.i)))
) %>%
dplyr::mutate(diag.A = case_when(delta == 1 ~ ((-1/(sigma.i**2))*exp(r.i)),
delta == 0 ~ ((-1/(sigma.i**2))*exp(r.i))))
#w.r.i <- (exp(r.i)-1)/r.i
u = ceramic.1$u
D = X.matrix
A = diag((-1)*c(ceramic.1$diag.A))
weighted.regr.y <- (solve(A) %*% u) + (D %*% beta.vector)
lm.fit <- lm(weighted.regr.y ~ D[,2], weights = diag(A))
beta.0.star <- lm.fit$coefficients[1]
beta.1.star <- lm.fit$coefficients[2]
beta.vector.star <- matrix(c(beta.0.star, beta.1.star), nrow = 2)
# sigma.star.squared <- (1/n)*sum(t(w.r.i) %*% (IRLSGreenTable2Data$y - (X.matrix %*% beta.vector.star))**2)
#
# sigma.star <- sqrt(sigma.star.squared)
ceramic.F <- ceramic.1 %>%
dplyr::filter(delta==1) %>%
dplyr::rowwise() %>%
dplyr::mutate(Fl = ((y - (c(1,logStress) %*% beta.vector.star))**2)*((exp(r.i)-1)/r.i)/(exp(2*beta.1s*logStress)))
# superAlloy.C <- superAlloy.1 %>%
#   dplyr::filter(delta==0) %>%
#   dplyr::rowwise() %>%
#   dplyr::mutate(Ce = ((y - (c(1,logStress,logStress2) %*% beta.vector.star))**2)*((exp(r.i))/r.i)/(exp(2*beta.1s*logStress)))
exp2beto.0s <- (1/(n.F))*(sum(ceramic.F$Fl))
# + sum(superAlloy.C$Ce))
#
beta.0s.star <- (1/2)*log(exp2beto.0s)
ceramic.F1 <- ceramic.1 %>%
dplyr::filter(delta==1) %>%
dplyr::rowwise() %>%
dplyr::mutate(Fl = ((y - (c(1,logStress) %*% beta.vector.star))**2)*((exp(r.i)-1)/r.i)*(logStress)/(exp(2*beta.0s.star)))
# superAlloy.C1 <- superAlloy.1 %>%
#   dplyr::filter(delta==0) %>%
#   dplyr::rowwise() %>%
#   dplyr::mutate(Ce = ((y - (c(1,logStress,logStress2) %*% beta.vector.star))**2)*((exp(r.i))/r.i)*(logStress)/(exp(2*beta.0s.star)))
beta.1sfn <- function(beta.1s){
sum(ceramic.F1$Fl/exp(2*beta.1s*ceramic.F1$logStress)) - sum(ceramic.F1$logStress)
# + sum(superAlloy.C1$Ce/exp(2*beta.1s*superAlloy.C1$logStress))
}
#uniroot(beta.1sfn, c(-1000,1000))
beta.1s.star <- uniroot(beta.1sfn, c(-10,10))$root
return(c(beta.0.star,beta.1.star,beta.0s.star,beta.1s.star))
}
# beta.0 <- 1
# beta.1 <- 0
# #beta.2 <- 0
# beta.0s <- 1
# beta.1s <- 0
#
# beta.0 <- beta.0.star
# beta.1 <- beta.1.star
# #beta.2 <- beta.2.star
# beta.0s <- beta.0s.star
# beta.1s <- beta.1s.star
beta.0_0 <- 1
beta.1_0 <- 0
#beta.2_0 <- 0
beta.0s_0 <- 1
beta.1s_0 <- 0
counter <- 1
repeat {
est.vector <- iterest(beta.0_0, beta.1_0,beta.0s_0,beta.1s_0)
beta.0 <- est.vector[1]
beta.1 <- est.vector[2]
#beta.2 <- est.vector[3]
beta.0s <- est.vector[3]
beta.1s <- est.vector[4]
if (abs(beta.0_0 - beta.0) & abs(beta.1_0 - beta.1) & abs(beta.0s - beta.0s_0) < 0.00001 & abs(beta.1s - beta.1s_0) < 0.00001) break
# sometimes, I might have to play around with the required accuracy (0.0001 vs 0.000001) to get an approximate value
beta.0_0 <- beta.0
beta.1_0 <- beta.1
#beta.2_0 <- beta.2
beta.0s_0 <- beta.0s
beta.1s_0 <- beta.1s
counter <- counter + 1
}
beta.0
beta.1
#beta.2
beta.0s
beta.1s
#Hessian
beta.vector.star <- matrix(c(beta.0, beta.1), nrow = 2)
betaStar.vector.star <- matrix(c(beta.0s, beta.1s), nrow = 2)
ceramic.F <- ceramic %>%
dplyr::filter(delta==1) %>%
dplyr::rowwise() %>%
dplyr::mutate(sigma.i = exp(c(1,logStress) %*% betaStar.vector.star)) %>%
dplyr::mutate(r.i = (y - (c(1,logStress) %*% beta.vector.star))/sigma.i)
# superAlloy.C <- superAlloy %>%
#   dplyr::filter(delta==0) %>%
#   dplyr::rowwise() %>%
#   dplyr::mutate(sigma.i = exp(c(1,logStress) %*% betaStar.vector.star)) %>%
#   dplyr::mutate(r.i = (y - (c(1,logStress,logStress2) %*% beta.vector.star))/sigma.i)
d2Ldbeta.02 <- H11 <- sum((-1/(ceramic.F$sigma.i**2))*exp(ceramic.F$r.i))
d2Ldbeta.0beta.1 <- H12 <- sum((-ceramic.F$logStress/(ceramic.F$sigma.i**2))*exp(ceramic.F$r.i))
d2Ldbeta.0beta.0s <- H13 <- sum((1/(ceramic.F$sigma.i))*(1 - exp(ceramic.F$r.i) - (ceramic.F$r.i*exp(ceramic.F$r.i))))
d2Ldbeta.0beta.1s <- H14 <- sum((ceramic.F$logStress/(ceramic.F$sigma.i))*(1 - exp(ceramic.F$r.i) - (ceramic.F$r.i*exp(ceramic.F$r.i))))
d2Ldbeta.12 <- H22 <- sum(-1/(ceramic.F$sigma.i**2)*(ceramic.F$logStress**2)*exp(ceramic.F$r.i))
d2Ldbeta.1beta.0s <- H23 <- sum((ceramic.F$logStress/ceramic.F$sigma.i)*(1 - exp(ceramic.F$r.i) - (ceramic.F$r.i*exp(ceramic.F$r.i))))
d2Ldbeta.1beta.1s <- H24 <- sum(((ceramic.F$logStress**2)/ceramic.F$sigma.i)*(1 - exp(ceramic.F$r.i) - (ceramic.F$r.i*exp(ceramic.F$r.i))))
d2Ldbeta.0s2 <- H33 <- sum((ceramic.F$r.i)*(1 - exp(ceramic.F$r.i) - (ceramic.F$r.i*exp(ceramic.F$r.i))))
d2Ldbeta.0sbeta.1s <- H34 <- sum((ceramic.F$logStress*ceramic.F$r.i)*(1 - exp(ceramic.F$r.i) - (ceramic.F$r.i*exp(ceramic.F$r.i))))
d2Ldbeta.1s2 <- H44 <- sum(((ceramic.F$logStress**2)*ceramic.F$r.i)*(1 - exp(ceramic.F$r.i) - (ceramic.F$r.i*exp(ceramic.F$r.i))))
hessian.matrix <- matrix(c(H11,H12,H13,H14,H12,H22,H23,H24,H13,H23,H33,H34,H14,H24,H34,H44), nrow = 4)
inf.matrix <- (-1)*hessian.matrix #Negative of Hessian is the information matrix when we maximize likelihood.
varcov <- solve(inf.matrix)
(std.er <- sqrt(diag(varcov)))
sigma.i_final <- exp(beta.0s + (beta.1s*ceramic$logStress))
r.i_final <- (ceramic$y-(beta.0 + (beta.1*ceramic$logStress)))/sigma.i_final
# Chunk 5: Prep ML table 1
RegrParas <- data.frame(
ML_est = c(beta.0, beta.1, beta.0s, beta.1s),
Std.Err = std.er)
RegrParas <- RegrParas %>%
dplyr::mutate(Wald_0.95_Lower = ML_est - (qnorm(0.975)*Std.Err),
Wald_0.95_Upper = ML_est + (qnorm(0.975)*Std.Err))
rownames(RegrParas) <- c("$\\hat{\\beta_{0}}$", "$\\hat{\\beta_{1}}$", "$\\hat{\\beta^{*}_{0}}$", "$\\hat{\\beta^{*}_{1}}$")
colnames(RegrParas) <- c("ML estimate","Standard Error","Wald Lower 95% CI","Wald Upper 95% CI")
Regr_LL <- round(sum((-log(sigma.i_final)) + r.i_final - exp(r.i_final) - log(ceramic$Revolutions)),3)
chisqStat <- 2*(Regr_LL - (-54.402))
p.val <- 1 - pchisq(chisqStat,1)
# Chunk 6: ML Table 1
knitr::kable(RegrParas, align = rep('c', 5), table.envir = 'table*', escape = FALSE, digits = 3) %>%
kableExtra::kable_styling("striped", full_width = T, position = "left")
# Chunk 7: Weibull plot varSig regression parameters
mu.0.87.varSig <- beta.0 + (beta.1*log(0.87))
sigma.0.87.varSig <- exp(beta.0s + (beta.1s*log(0.87)))
mu.0.99.varSig <- beta.0 + (beta.1*log(0.99))
sigma.0.99.varSig <- exp(beta.0s + (beta.1s*log(0.99)))
mu.1.09.varSig <- beta.0 + (beta.1*log(1.09))
sigma.1.09.varSig <- exp(beta.0s + (beta.1s*log(1.09)))
mu.1.18.varSig <- beta.0 + (beta.1*log(1.18))
sigma.1.18.varSig <- exp(beta.0s + (beta.1s*log(1.18)))
# Chunk 8: Weibull plot prep
#Fig 17.7 a and b equivalent for ceramic data
##I need the Kaplan Meir estimates of the CDF for each level of stress. Instead of coding 4 separate times for 4 stress levels, I am going to loop it.
uniqueStress <- sort(unique(ceramic$Stress))
Fig17_CDF <- list() #Non parametric CDF estimates for all plots in Fig 17
Fig17.a_MLest <- list() #Maximum likelihood estimates of plot (a) i.e lognormal
Fig17.b_MLest <- list() #Maximum likelihood estimates of plot (b) i.e weibull
i <- 1
while(i <= length(uniqueStress)){
df <- ceramic %>%
dplyr::filter(Stress == uniqueStress[i])
fit_df <- survival::survfit(Surv(Revolutions, delta) ~ 1, data = df)
temp_df <- data.frame(Revolutions = fit_df$time,
p = 1-fit_df$surv)
temp_df <- temp_df %>%
dplyr::mutate(bottomOfStairs = c(0,head(p,-1))) %>%
dplyr::mutate(middleOfStairs = (p + bottomOfStairs)/2) %>% #Note: p is top of stairs.
dplyr::select(!p) %>%
dplyr::rename(p = middleOfStairs) #This piece of code is for plotting the CDF at the mid point of the jumps instead of plotting at the top of the jumps. See Section 6.4.2 of Chapter 6 in SMRD2.
Fig17_CDF[[i]] <- temp_df
para_fit_logNormal <- survival::survreg(Surv(Revolutions, delta) ~ 1, data = df, dist = "lognormal")
Fig17.a_MLest[[i]] <- c(
para_fit_logNormal[["coefficients"]], #mu
para_fit_logNormal[["scale"]], #sigma
para_fit_logNormal[["loglik"]][2], #log likelihood
sqrt(para_fit_logNormal[["var"]][1, 1]), #s.e of mu
(para_fit_logNormal[["scale"]] * sqrt(para_fit_logNormal[["var"]][2, 2])) #s.e of scale
)
para_fit_weibull <- survival::survreg(Surv(Revolutions, delta) ~ 1, data = df, dist = "weibull")
Fig17.b_MLest[[i]] <- c(
para_fit_weibull[["coefficients"]], #mu
para_fit_weibull[["scale"]], #sigma
para_fit_weibull[["loglik"]][2], #log-likelihood
sqrt(para_fit_weibull[["var"]][1, 1]), #s.e of mu
(para_fit_weibull[["scale"]] * sqrt(para_fit_weibull[["var"]][2, 2])) #s.e of sigma
)
i = i + 1
}
names(Fig17_CDF) <- uniqueStress
names(Fig17.a_MLest) <- uniqueStress
names(Fig17.b_MLest) <- uniqueStress
#In order to linearize a log-normal distribution, log(t.p) vs phi inverse(p) plots as a straight line. See Section 6.2.3 in SMRD2. We will now code the 2 transformers for X and Y axes for log-normal
xTransformer.logNormal <- scales::trans_new(
name = "logNormal.x.transform",
transform = function(t.p){
x = log(t.p)
return(x)
},
inverse = function(x) {
t.p = exp(x)
return(t.p)
}
)
yTransfomer.logNormal <- scales::trans_new(
name = "logNormal.y.transform",
transform = function(p){
y = qnorm(p)
return(y)
},
inverse = function(y) {
p = pnorm(y)
return(p)
}
)
#In order to linearize a weibull distribution, log(t.p) vs log[-log(1-p)] plots as a straight line. See Section 6.2.4 in SMRD2. We will now code the 2 transformers for X and Y axes for weibull
xTransformer.weibull <- scales::trans_new(
name = "weibull.x.transform",
transform = function(t.p){
x = log(t.p)
return(x)
},
inverse = function(x) {
t.p = exp(x)
return(t.p)
}
)
yTransfomer.weibull <- scales::trans_new(
name = "weibull.y.transform",
transform = function(p){
y = log(-log(1-p))
return(y)
},
inverse = function(y) {
p = 1 - exp(-exp(y))
return(p)
}
)
# Chunk 9: Weibull plot varSig Regression
#Weibull plot 17.10 d
cols <- c("0.87 Mpsi"="red","0.99 Mpsi"="blue","1.09 Mpsi"="green","1.18 Mpsi"="orange")
ggplot() + geom_point(
data = Fig17_CDF[["0.87"]],
aes(x = Revolutions, y = p, color = "0.87 Mpsi")
) + geom_point(
data = Fig17_CDF[["0.99"]],
aes(x = Revolutions, y = p, color = "0.99 Mpsi"),
) + geom_point(
data = Fig17_CDF[["1.09"]],
aes(x = Revolutions, y = p, color = "1.09 Mpsi")
) + geom_point(
data = Fig17_CDF[["1.18"]],
aes(x = Revolutions, y = p, color = "1.18 Mpsi")
) + scale_x_continuous(
transform = xTransformer.weibull,
name = "Hours",
breaks = c(10,50,100,250,500, 1000,1100)
) + scale_y_continuous(
transform = yTransfomer.weibull,
name = "Fraction Failing",
breaks = seq(0.00,0.99,0.05)
) + geom_abline(
aes(intercept = (-mu.0.87.varSig/sigma.0.87.varSig), #y-axis intercept
slope = 1/sigma.0.87.varSig, color = "0.87 Mpsi")
) + geom_abline(
aes(intercept = (-mu.0.99.varSig/sigma.0.99.varSig), #y-axis intercept
slope = 1/sigma.0.99.varSig, color = "0.99 Mpsi")
) + geom_abline(
aes(intercept = (-mu.1.09.varSig/sigma.1.09.varSig), #y-axis intercept
slope = 1/sigma.1.09.varSig, color = "1.09 Mpsi")
) + geom_abline(
aes(intercept = (-mu.1.18.varSig/sigma.1.18.varSig), #y-axis intercept
slope = 1/sigma.1.18.varSig, color = "1.18 Mpsi")
) + ggtitle(label = "Weibull Plot for Varying Shape Regression Model") + scale_color_manual(name="Stress",values = cols)
# Chunk 10: Quantile Calculation
#here are the quantiles and their standard errors for the constant shape model
para_fit_weibull.Fig17.10d <- survival::survreg(Surv(Revolutions, delta) ~ log(Stress), data = ceramic, dist = "weibull")
quantiles_0.1_0.5 <- predict(para_fit_weibull.Fig17.10d,
newdata = data.frame(Stress = 1.15), type = 'quantile', p=c(0.1,0.5), se.fit = T)
lower_wald95 <- exp(log(quantiles_0.1_0.5$fit) - (qnorm(0.975)*quantiles_0.1_0.5$se.fit/quantiles_0.1_0.5$fit))
upper_wald95 <- exp(log(quantiles_0.1_0.5$fit) + (qnorm(0.975)*quantiles_0.1_0.5$se.fit/quantiles_0.1_0.5$fit))
#here are the quantiles and their standard errors from the varying shape parameter model. These requre the delta method to calculate. See your hand written notes.
z.10 = log(-log(1-0.1))
z.50 = log(-log(1-0.5))
quantile_0.1_varSig <- exp(beta.0 + (beta.1*log(1.15)) + (z.10*exp(beta.0s + (beta.1s*log(1.15)))))
quantile_0.5_varSig <- exp(beta.0 + (beta.1*log(1.15)) + (z.50*exp(beta.0s + (beta.1s*log(1.15)))))
#A on page 13-C in your notes
A <- varcov[1,1] + (((log(1.15))**2)*varcov[2,2]) + (2*(log(1.15))*varcov[1,2])
#B on page 14-C in your notes
B <- (((exp(beta.0s + (beta.1s*log(1.15))))**2)*varcov[3,3]) + (((log(1.15)*exp(beta.0s + (beta.1s*log(1.15))))**2)*varcov[4,4]) + ((log(1.15)*((exp(beta.0s + (beta.1s*log(1.15))))**2))*varcov[3,4])
#C on pages 16-C and 17-C
C <- ((exp(beta.0s + (beta.1s*log(1.15))))*varcov[1,3]) + (log(1.15)*(exp(beta.0s + (beta.1s*log(1.15))))*varcov[1,4]) + (log(1.15)*(exp(beta.0s + (beta.1s*log(1.15))))*varcov[2,3]) + (((log(1.15))**2)*(exp(beta.0s + (beta.1s*log(1.15))))*varcov[2,4])
Var_Log.quantile_0.1_varSig <- A + ((z.10**2)*B) + (2*z.10*C)
std.err_Log.quantile_0.1_varSig <- sqrt(Var_Log.quantile_0.1_varSig)
std.err_quantile_0.1_varSig <- quantile_0.1_varSig*std.err_Log.quantile_0.1_varSig
lower_wald95_quantile_0.1_varSig <- exp(log(quantile_0.1_varSig) - (qnorm(0.975)*std.err_Log.quantile_0.1_varSig))
upper_wald95_quantile_0.1_varSig <- exp(log(quantile_0.1_varSig) + (qnorm(0.975)*std.err_Log.quantile_0.1_varSig))
Var_Log.quantile_0.5_varSig <- A + ((z.50**2)*B) + (2*z.50*C)
std.err_Log.quantile_0.5_varSig <- sqrt(Var_Log.quantile_0.5_varSig)
std.err_quantile_0.5_varSig <- quantile_0.5_varSig*std.err_Log.quantile_0.5_varSig
lower_wald95_quantile_0.5_varSig <- exp(log(quantile_0.5_varSig) - (qnorm(0.975)*std.err_Log.quantile_0.5_varSig))
upper_wald95_quantile_0.5_varSig <- exp(log(quantile_0.5_varSig) + (qnorm(0.975)*std.err_Log.quantile_0.5_varSig))
#data frame of quantiles
quantile_df <- data.frame(t.p = c(quantiles_0.1_0.5$fit,quantile_0.1_varSig,quantile_0.5_varSig), t.p.se = c(quantiles_0.1_0.5$se.fit,std.err_quantile_0.1_varSig,std.err_quantile_0.5_varSig), wald_lower = c(lower_wald95,lower_wald95_quantile_0.1_varSig,lower_wald95_quantile_0.5_varSig),
wald_upper = c(upper_wald95,upper_wald95_quantile_0.1_varSig,upper_wald95_quantile_0.5_varSig))
quantile_df<- quantile_df %>%
dplyr::mutate(quantile = c("$\\hat{t_{0.1}}$","$\\hat{t_{0.5}}$","$\\hat{t_{0.1}}$","$\\hat{t_{0.5}}$")) %>%
dplyr::select(quantile, everything()) %>%
dplyr::mutate(Model = c(rep("Constant Shape",2),rep("Varying Shape",2))) %>%
dplyr::select(Model, everything())
#rownames(quantile_df) <- c("$\\hat{t_{0.1}}$","$\\hat{t_{0.5}}$","$\\hat{t_{0.1}}$","$\\hat{t_{0.5}}$")
# rownames(quantile_df) <- c("Constant Shape","Constant Shape1","Varying Shape","Varying Shape1")
colnames(quantile_df) <- c("Model","Quantile","ML estimate","Standard Error","Wald Lower 95% CI","Wald Upper 95% CI")
# Chunk 11: ML Table 5
t <- knitr::kable(quantile_df, align = rep('c', 5), table.envir = 'table*', escape = FALSE, digits = 3) %>%
kableExtra::kable_styling("striped", full_width = T, position = "left")
kableExtra::collapse_rows(t)
#, caption = "Table 2. Maximum Likelihood estimates"
# Chunk 12: Std. Residuals vs Fitted Values prep
#First, add a column for the linear predictors. This is nothing but "mu + gamma.transpose*Z" for every observation.
ceramic <- ceramic %>%
dplyr::mutate(LinearPredictor = beta.0 + (beta.1*log(Stress)))
#Next, add a column for standardized residuals. The definition of standardized residual for a log-location-scale model is given by Eq 17.12 in SMRD2
ceramic <- ceramic %>%
dplyr::mutate(sigma.i = exp(beta.0s + (beta.1s*log(Stress)))) %>%
dplyr::mutate(stdResid = exp((log(Revolutions)-LinearPredictor)/sigma.i)) %>%
dplyr::mutate(stdResid.round = round(stdResid,3))
# Chunk 13: Std Resid vs fitted values
ggplot(ceramic, aes(x = exp(LinearPredictor), y = stdResid, group = delta)) + geom_point() + coord_trans(x = 'log', y = 'log') + ylab("Standardized Residuals") + xlab("Fitted Values") #Matches figure 17.5a! Notice that the variability is higher at larger fitted values.
#+ geom_point(aes(shape = factor(delta, levels = c(1,0))))
# Chunk 14: Std. Residuals Weibull Plot prep
#Next, we will plot a Weibull plot of the standardized residuals. In order to plot a Weibull plot, I need to plot log(t.p) vs log[-log(1-p)] as per Section 6.2.4 in SMRD2. Note that (1-p) is nothing but the Kaplan Meir survival probability (because p is the CDF).
#First, I need the Kaplan Meir estimate of the CDF of the standardized residuals
fitModel1.KaplanMeir <- survival::survfit(Surv(stdResid.round,delta) ~ 1, data = ceramic)
summary(fitModel1.KaplanMeir)
#Next, I need the confidence band. I tried using the survMisc package, but the confidence bands I was getting did not make sense. The survival lower and upper bounds of the survival probability band increased at some times, which does not make sense because survival function is strictly non-increasing. The survMisc package is from 2016 and is very old. I used the km.ci package with the log transformed Equal probability band and even this gave me confidence bands where the survival function increased at some point. After reading the section on confidence bands in SMRD2 (Section 3.8 in Chapter 3), I realized that it is possible that sometimes this can happen. Don't panic! All you need to do is adjust the confidence bands as mentioned in the Section 3.8. Here is what you need to do to adjust the bands: "If the upper band is decreasing on the left, it is made flat from tL(a) to the point of the minimum. If the lower band is decreasing on the right, it is made flat from the point of maximum to tU(b) . These adjustments, if needed, give tighter, more sensible bands and have no effect on the actual coverage probability of the nonparametric simultaneous bands." This is also mentioned in SAS documentation here: "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_lifetest_details11.htm", but it references the same SMRD2 book.
#Also, the latest version of the km.ci package is from 2022 and is newer as compared to survMisc. Going forward, I should use km.ci for confidence bands and not survMisc.
#survFitObject <- survival::survfit(Surv(stdResid.round,delta) ~ 1, data = ceramic) #Required for km.ci on the next line.
confBands2 <- km.ci::km.ci(fitModel1.KaplanMeir, conf.level = 0.95, method = "logep") #"logep" recommended by km.ci package documentation.
#create a dataframe with all the probabilities that I need to plot
weibullPlot.model1 <- data.frame(t.p = fitModel1.KaplanMeir[["time"]],
survival.p = fitModel1.KaplanMeir[["surv"]]) %>%
dplyr::mutate(p = 1 - survival.p) %>%
dplyr::filter(row_number() <= n()-1) %>% #The observation with survival probability 0 i.e. the last observation is removed since we cannot have confidence band values for this observation.
dplyr::mutate(survival.lower = confBands2$lower,
survival.upper = confBands2$upper) %>%
dplyr::mutate(p.lower = round(1 - survival.upper,3),
p.upper = round(1 - survival.lower,3))
xTransformer <- scales::trans_new(
name = "weibull.x.transform",
transform = function(t.p){
x = log(t.p)
return(x)
},
inverse = function(x) {
t.p = exp(x)
return(t.p)
}
)
yTransfomer <- scales::trans_new(
name = "weibull.y.transform",
transform = function(p){
y = log(-log(1-p))
return(y)
},
inverse = function(y) {
p = 1 - exp(-exp(y))
return(p)
}
)
#Plot Fig 17.5 b
ggplot(weibullPlot.model1, aes(x = t.p, y = p)) + geom_point() + geom_step(aes(y = p.lower)) + geom_step(aes(y = p.upper)) + scale_x_continuous(transform = xTransformer, name = "Standardized Residuals", breaks = c(0.001,0.01, 0.1, 1)) + scale_y_continuous(transform = yTransfomer, name = "Probability",breaks = seq(0.01,0.99,0.05))
#Notice that the upper bound of the confidence band decreases at a point. Hence, an adjustment, as discussed above, is needed.
weibullPlot.model1$p.upper[c(1)] <- weibullPlot.model1$p.upper[2]
#Plot 17.5b again, with the adjusted upper band.
# Chunk 15: Std Resid Weibull plot
std.resid.prob.plot <- ggplot(weibullPlot.model1, aes(x = t.p, y = p)) + geom_point() + geom_step(aes(y = p.lower)) + geom_step(aes(y = p.upper)) + scale_x_continuous(transform = xTransformer, name = "Standardized Residuals", breaks = c(0.001,0.01, 0.1, 1,2,3)) + scale_y_continuous(transform = yTransfomer, name = "Probability",breaks = seq(0.01,0.99,0.1))
R <- suppressWarnings(print(std.resid.prob.plot))
# Chunk 16
report::cite_packages()
# Chunk 17: flexsurv
fs1 <- flexsurv::flexsurvreg(Surv(Revolutions, delta) ~ log(Stress) + shape(log(Stress)), data = ceramic, dist = "weibull")
fs1
fs_quantile <- predict(fs1,
newdata = data.frame(Stress = 1.15), type = 'quantile', p=c(0.1,0.5), se.fit = T)
#flexsurv output matches my manual calculation output!!
