#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 5")) + scale_x_continuous(
transform = xTransformer.weibull,
name = "Strength",
breaks = c(5, 10, 20, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000)
) + scale_y_continuous(
transform = yTransfomer.weibull,
name = "Fraction Failing",
breaks = c(
0.00003,
0.0001,
0.0002,
0.0005,
0.001,
0.003,
0.01,
0.02,
0.05,
0.1,
0.2,
0.5,
0.7,
0.9
)
)  + ggtitle(expression(paste("Weibull Probability Plot (Equal $\\sigma$)"))) + scale_color_manual(name =
"Batch", values = cols)
ggplot() + geom_point(data = CDF_Batch1.df, aes(x = Strength, y = p, color = "Batch 1")) + geom_abline(aes(
intercept = (-mu.ML_Batch1_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 1")) + geom_point(data = CDF_Batch4.df, aes(x = Strength, y = p, color = "Batch 4")) + geom_abline(aes(
intercept = (-mu.ML_Batch4_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 4")) + geom_point(data = CDF_Batch5.df, aes(x = Strength, y = p, color = "Batch 5")) + geom_abline(aes(
intercept = (-mu.ML_Batch5_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 5")) + scale_x_continuous(
transform = xTransformer.weibull,
name = "Strength",
breaks = c(5, 10, 20, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000)
) + scale_y_continuous(
transform = yTransfomer.weibull,
name = "Fraction Failing",
breaks = c(
0.00003,
0.0001,
0.0002,
0.0005,
0.001,
0.003,
0.01,
0.02,
0.05,
0.1,
0.2,
0.5,
0.7,
0.9
)
)  + ggtitle(expression(paste("Weibull Probability Plot (Equal", $\\sigma$)))) + scale_color_manual(name =
ggplot() + geom_point(data = CDF_Batch1.df, aes(x = Strength, y = p, color = "Batch 1")) + geom_abline(aes(
intercept = (-mu.ML_Batch1_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 1")) + geom_point(data = CDF_Batch4.df, aes(x = Strength, y = p, color = "Batch 4")) + geom_abline(aes(
intercept = (-mu.ML_Batch4_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 4")) + geom_point(data = CDF_Batch5.df, aes(x = Strength, y = p, color = "Batch 5")) + geom_abline(aes(
intercept = (-mu.ML_Batch5_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 5")) + scale_x_continuous(
transform = xTransformer.weibull,
name = "Strength",
breaks = c(5, 10, 20, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000)
) + scale_y_continuous(
transform = yTransfomer.weibull,
name = "Fraction Failing",
breaks = c(
0.00003,
0.0001,
0.0002,
0.0005,
0.001,
0.003,
0.01,
0.02,
0.05,
0.1,
0.2,
0.5,
0.7,
0.9
)
)  + ggtitle(expression(paste("Weibull Probability Plot (Equal", sigma))) + scale_color_manual(name =
"Batch", values = cols)
ggplot() + geom_point(data = CDF_Batch1.df, aes(x = Strength, y = p, color = "Batch 1")) + geom_abline(aes(
intercept = (-mu.ML_Batch1_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 1")) + geom_point(data = CDF_Batch4.df, aes(x = Strength, y = p, color = "Batch 4")) + geom_abline(aes(
intercept = (-mu.ML_Batch4_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 4")) + geom_point(data = CDF_Batch5.df, aes(x = Strength, y = p, color = "Batch 5")) + geom_abline(aes(
intercept = (-mu.ML_Batch5_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 5")) + scale_x_continuous(
transform = xTransformer.weibull,
name = "Strength",
breaks = c(5, 10, 20, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000)
) + scale_y_continuous(
transform = yTransfomer.weibull,
name = "Fraction Failing",
breaks = c(
0.00003,
0.0001,
0.0002,
0.0005,
0.001,
0.003,
0.01,
0.02,
0.05,
0.1,
0.2,
0.5,
0.7,
0.9
)
)  + ggtitle(expression(paste("Weibull Probability Plot (Equal ", sigma))) + scale_color_manual(name =
"Batch", values = cols)
ggplot() + geom_point(data = CDF_Batch1.df, aes(x = Strength, y = p, color = "Batch 1")) + geom_abline(aes(
intercept = (-mu.ML_Batch1_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 1")) + geom_point(data = CDF_Batch4.df, aes(x = Strength, y = p, color = "Batch 4")) + geom_abline(aes(
intercept = (-mu.ML_Batch4_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 4")) + geom_point(data = CDF_Batch5.df, aes(x = Strength, y = p, color = "Batch 5")) + geom_abline(aes(
intercept = (-mu.ML_Batch5_EqualSig.Weibull / sigma.EqualSig),
#y-axis intercept
slope = 1 / sigma.EqualSig
, color = "Batch 5")) + scale_x_continuous(
transform = xTransformer.weibull,
name = "Strength",
breaks = c(5, 10, 20, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000)
) + scale_y_continuous(
transform = yTransfomer.weibull,
name = "Fraction Failing",
breaks = c(
0.00003,
0.0001,
0.0002,
0.0005,
0.001,
0.003,
0.01,
0.02,
0.05,
0.1,
0.2,
0.5,
0.7,
0.9
)
)  + ggtitle(expression(paste("Weibull Probability Plot (Equal ", sigma,")"))) + scale_color_manual(name =
"Batch", values = cols)
diffInlogMedian_41 <- fit_3$coefficients[2] #Use a positive difference i.e. don't do Op1 - Op2. You can do it if you want, but the delta will be negative, and both CI limits will be -ve as well. Interpretation will be slightly tricky. Thats it.
se_diffInlogMedian_41 <- sqrt(fit_3$var[2,2])
diffInlogMedian_41_lowerWald <- diffInlogMedian_41 - (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_41)
diffInlogMedian_41_upperWald <- diffInlogMedian_41 + (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_41)
diffInlogMedian_51 <- fit_3$coefficients[3]
se_diffInlogMedian_51 <- sqrt(fit_3$var[3,3])
diffInlogMedian_51_lowerWald <- diffInlogMedian_51 - (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_51)
diffInlogMedian_51_upperWald <- diffInlogMedian_51 + (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_51)
diffInlogMedian_54 <- fit_3$coefficients[3] - fit_3$coefficients[2]
se_diffInlogMedian_54 <- sqrt(fit_3$var[3,3] + fit_3$var[2,2] - (2*fit_3$var[2,3]))
diffInlogMedian_54_lowerWald <- diffInlogMedian_54 - (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_54)
diffInlogMedian_54_upperWald <- diffInlogMedian_54 + (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_54)
delta_median.df <- data.frame(Delta = c("$\\Delta_{41}$", "$\\Delta_{51}$", "$\\Delta_{54}$"),
Estimate = c(diffInlogMedian_41, diffInlogMedian_51, diffInlogMedian_54),
Std.Error = c(se_diffInlogMedian_41, se_diffInlogMedian_51, se_diffInlogMedian_54),
lower.CI = c(diffInlogMedian_41_lowerWald, diffInlogMedian_51_lowerWald, diffInlogMedian_54_lowerWald),
upper.CI = c(diffInlogMedian_41_upperWald, diffInlogMedian_51_upperWald, diffInlogMedian_54_upperWald))
colnames(delta_median.df) <- c("Delta", "ML Estimate", "Standard Error", "Simulataneous approximate 90% CI (Lower)", "Simulataneous approximate 90% CI (Upper)")
n <- knitr::kable(delta_median.df, align = rep('c', 5), table.envir = 'table*', escape = FALSE, digits = 3) %>%
kableExtra::kable_styling("striped", full_width = T, position = "left")
n
#Median for the 3 operators from SepDists model
median_Batch1 <- predict(fit_2.Batch1.Weibull, type = "quantile", p = 0.5, se.fit = T)$fit[1]
se_median_Batch1 <- predict(fit_2.Batch1.Weibull, type = "quantile", p = 0.5, se.fit = T)$se.fit[1]
logMedian_Batch1 <- log(median_Batch1) #Needed to replicate Table 12.6
se_logMedian_Batch1 <- se_median_Batch1/median_Batch1 #Needed to replicate Table 12.6
median_Batch4 <- predict(fit_2.Batch4.Weibull, type = "quantile", p = 0.5, se.fit = T)$fit[1]
se_median_Batch4 <- predict(fit_2.Batch4.Weibull, type = "quantile", p = 0.5, se.fit = T)$se.fit[1]
logMedian_Batch4 <- log(median_Batch4) #Needed to replicate Table 12.6
se_logMedian_Batch4 <- se_median_Batch4/median_Batch4 #Needed to replicate Table 12.6
median_Batch5 <- predict(fit_2.Batch5.Weibull, type = "quantile", p = 0.5, se.fit = T)$fit[1]
se_median_Batch5 <- predict(fit_2.Batch5.Weibull, type = "quantile", p = 0.5, se.fit = T)$se.fit[1]
logMedian_Batch5 <- log(median_Batch5) #Needed to replicate Table 12.6
se_logMedian_Batch5 <- se_median_Batch5/median_Batch5 #Needed to replicate Table 12.6
diffInlogMedian_41 <- logMedian_Batch4 -logMedian_Batch1 #Use a positive difference i.e. don't do Op1 - Op2. You can do it if you want, but the delta will be negative, and both CI limits will be -ve as well. Interpretation will be slightly tricky. Thats it.
se_diffInlogMedian_41 <- sqrt((se_logMedian_Batch1**2) + (se_logMedian_Batch4**2))
diffInlogMedian_41_lowerWald <- diffInlogMedian_41 - (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_41)
diffInlogMedian_41_upperWald <- diffInlogMedian_41 + (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_41)
diffInlogMedian_51 <- logMedian_Batch5 -logMedian_Batch1
se_diffInlogMedian_51 <- sqrt((se_logMedian_Batch1**2) + (se_logMedian_Batch5**2))
diffInlogMedian_51_lowerWald <- diffInlogMedian_51 - (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_51)
diffInlogMedian_51_upperWald <- diffInlogMedian_51 + (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_51)
diffInlogMedian_54 <- logMedian_Batch5 -logMedian_Batch4
se_diffInlogMedian_54 <- sqrt((se_logMedian_Batch4**2) + (se_logMedian_Batch5**2))
diffInlogMedian_54_lowerWald <- diffInlogMedian_54 - (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_54)
diffInlogMedian_54_upperWald <- diffInlogMedian_54 + (qnorm(1-((0.1/3)/2))*se_diffInlogMedian_54)
delta_median.df <- data.frame(Delta = c("$\\Delta_{41}$", "$\\Delta_{51}$", "$\\Delta_{54}$"),
Estimate = c(diffInlogMedian_41, diffInlogMedian_51, diffInlogMedian_54),
Std.Error = c(se_diffInlogMedian_41, se_diffInlogMedian_51, se_diffInlogMedian_54),
lower.CI = c(diffInlogMedian_41_lowerWald, diffInlogMedian_51_lowerWald, diffInlogMedian_54_lowerWald),
upper.CI = c(diffInlogMedian_41_upperWald, diffInlogMedian_51_upperWald, diffInlogMedian_54_upperWald))
colnames(delta_median.df) <- c("Delta", "ML Estimate", "Standard Error", "Simulataneous approximate 90% CI (Lower)", "Simulataneous approximate 90% CI (Upper)")
m <- knitr::kable(delta_median.df, align = rep('c', 5), table.envir = 'table*', escape = FALSE, digits = 3) %>%
kableExtra::kable_styling("striped", full_width = T, position = "left")
m
#Contour plot
df_Batch1 <-  bondStrength[which(bondStrength$Batch == "Batch1"),]
df_Batch4 <-  bondStrength[which(bondStrength$Batch == "Batch4"),]
df_Batch5 <-  bondStrength[which(bondStrength$Batch == "Batch5"),]
loglik1 <- function(df,mu,sigma){
failures.df <- df %>%
dplyr::filter(delta == 1)
censored.df <- df %>%
dplyr::filter(delta == 0)
r.i.F <- (log(failures.df$Strength) - mu)/sigma
r.i.C <- (log(censored.df$Strength) - mu)/sigma
ll <- sum(-log(sigma)-log(failures.df$Strength) + r.i.F - exp(r.i.F)) + sum(-exp(r.i.C)) # I added the "-log(ailures.df$Strength)" here so that the log likelihood matches survival package results
ll
}
# Create a grid of parameter values. Note that you should only create a grid for the "X" and "Y" parameters on the contour plot that you want to plot. For example, we want to print contour plot of the median vs beta here. So, we will create a grid of median vs beta, as shown below. If I wanted mu and sigma contour plot, I would create a grid of mu and sigma, like I did in Chapter 8.
beta_range <- seq(1,8, length = 100)
t.p_range <- seq(200, 1000, length=100)
grid <- expand.grid(median = t.p_range, beta = beta_range)
qsev_0.5 <- log(-log(1-0.5))
loglik.Batch1_ML <- fit_2.Batch1.Weibull$loglik[2]
loglik.Batch4_ML <- fit_2.Batch4.Weibull$loglik[2]
loglik.Batch5_ML <- fit_2.Batch5.Weibull$loglik[2]
#test_fit$
#summary(test_fit)
grid <- grid %>%
dplyr::mutate(sigma = 1/beta) %>%
dplyr::mutate(mu = log(median) - (qsev_0.5*sigma)) %>%
dplyr::rowwise() %>%
dplyr::mutate(ll_Batch1 = loglik1(df_Batch1,mu,sigma),
ll_Batch4 = loglik1(df_Batch4,mu,sigma),
ll_Batch5 = loglik1(df_Batch5,mu,sigma)) %>%
dplyr::mutate(RelLik_Batch1 = exp(ll_Batch1)/exp(loglik.Batch1_ML),
RelLik_Batch4 = exp(ll_Batch4)/exp(loglik.Batch4_ML),
RelLik_Batch5 = exp(ll_Batch5)/exp(loglik.Batch5_ML)) %>%
dplyr::mutate(confidenceRegion_Batch1 = 100*(1-RelLik_Batch1),
confidenceRegion_Batch4 = 100*(1-RelLik_Batch4),
confidenceRegion_Batch5 = 100*(1-RelLik_Batch5))
# Create the contour plot for Op1
a <- ggplot() +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch1),
breaks = c(90),
col = "black"
) +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch4),
breaks = c(90),
col = "red"
) +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch5),
breaks = c(90),
col = "green"
) +
scale_x_continuous(breaks = seq(200, 850, 50), limits = c(200,850)) +
scale_y_continuous(breaks = seq(1,8,0.5), limits = c(1,8)) +
labs(x = "median", y = "beta", title = "Relative Likelihood Contours") #Looks like plot 12.4 (b)!! Notice that the 95% confidence regions do not overlap. This means that we have evidence at the 5% significance level to claim that the time to failure for the 3 operators are different (statistical significance)
suppressWarnings(a)
# Create the contour plot for Op1
suppressWarnings({
a <- ggplot() +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch1),
breaks = c(90),
col = "black"
) +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch4),
breaks = c(90),
col = "red"
) +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch5),
breaks = c(90),
col = "green"
) +
scale_x_continuous(breaks = seq(200, 850, 50), limits = c(200,850)) +
scale_y_continuous(breaks = seq(1,8,0.5), limits = c(1,8)) +
labs(x = "median", y = "beta", title = "Relative Likelihood Contours") #Looks like plot 12.4 (b)!! Notice that the 95% confidence regions do not overlap. This means that we have evidence at the 5% significance level to claim that the time to failure for the 3 operators are different (statistical significance)
})
a
print(a)
# Create the contour plot for Op1
suppressWarnings({
a <- ggplot() +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch1),
breaks = c(90),
col = "black"
) +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch4),
breaks = c(90),
col = "red"
) +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch5),
breaks = c(90),
col = "green"
) +
scale_x_continuous(breaks = seq(200, 850, 50), limits = c(200,850)) +
scale_y_continuous(breaks = seq(1,8,0.5), limits = c(1,8)) +
labs(x = "median", y = "beta", title = "Relative Likelihood Contours") #Looks like plot 12.4 (b)!! Notice that the 95% confidence regions do not overlap. This means that we have evidence at the 5% significance level to claim that the time to failure for the 3 operators are different (statistical significance)
})
print(a)
suppressWarnings(print(a))
cols <- c("Batch 1"="red","Batch 4"="blue","Batch 5"="green")
a <- ggplot() +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch1,
col = "Batch 1"),
breaks = c(90)
) +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch4,
col = "Batch 4"),
breaks = c(90)
) +
geom_contour(
data = grid,
aes(x = median, y =  beta, z = confidenceRegion_Batch5,
col = "Batch 5"),
breaks = c(90)
) +
scale_x_continuous(breaks = seq(200, 850, 50), limits = c(200,850)) +
scale_y_continuous(breaks = seq(1,8,0.5), limits = c(1,8)) +
labs(x = "median", y = "beta", title = "Relative Likelihood Contours") + #Looks like plot 12.4 (b)!! Notice that the 95% confidence regions do not overlap. This means that we have evidence at the 5% significance level to claim that the time to failure for the 3 operators are different (statistical significance)
ggtitle(label = "Confidence Regions") + scale_color_manual(name =
"Batch", values = cols)
suppressWarnings(print(a))
library(tufte)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
library(survival)
library(tidyverse)
library(readr)
library(survminer)
library(kableExtra)
library(flexsurv)
library(gridExtra)
library(km.ci)
setwd("G:/My Drive/rao@ualberta.ca 2022-12-08 10 58/shishir@tamu.edu/My Drive/Interesting papers/Survival Models/GitHub/Survival/Survival-Analysis/Blog 7")
bondStrength <- read_csv("Data/BondStrength.csv", show_col_types = FALSE)
install.packages("tufte")
library(tufte)
library(tufte)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
library(RSplida)
library(RSplida)
library(survival)
library(tidyverse)
library(readr)
library(survminer)
library(kableExtra)
library(flexsurv)
library(gridExtra)
library(km.ci)
eta <- 75000
beta <- 1.4
mu <- log(75000)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 25000
beta <- 1.4
mu <- log(75000)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 25000
beta <- 1.4
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 5000
beta <- 1.4
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 5000
beta <- 7.3
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 5000
beta <- 1.1
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 20000
beta <- 1.1
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 4.8091e6
beta <- 1.1
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 4.8091e6
beta <- 7.3
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 192
beta <- 14.5
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 20000
beta <- 1.4
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 75000
beta <- 1.4
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 25000
beta <- 1.4
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 25000
beta <- 1.4
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 25000
beta <- 1.4
mu <- log(eta)
sigma <- 1/beta
t0.1 <- exp(mu + (qsev(0.1)*sigma))
eta <- 25000
beta <- 1.4
mu <- log(eta)
sigma <- 1/beta
p <- 0.05
tp <- exp(mu + (qsev(p)*sigma))
eta <- 25000
beta <- 1.4
mu <- log(eta)
sigma <- 1/beta
p <- 0.05
tp <- exp(mu + (qsev(p)*sigma))
tc <- 4000
psev((log(4000) - mu)/sigma)
prop.failing <- psev((log(4000) - mu)/sigma)
varianceFactorQuantile(0.05,prop.failing,"sev")
prop.failing <- psev((log(50) - 4.81)/0.5)
varianceFactorQuantile(0.05,prop.failing,"sev")
varianceFactorQuantile(0.1,prop.failing,"sev")
prop.failing <- psev((log(4000) - mu)/sigma)
qnorm(0.95)
n <- (qnorm(0.95)**2)*(sigma**2)*V.yp/(log(2)**2)
prop.failing <- psev((log(4000) - mu)/sigma)
V.yp <- varianceFactorQuantile(0.05,prop.failing,"sev")
n <- (qnorm(0.95)**2)*(sigma**2)*V.yp/(log(2)**2)
n <- ceiling(n)
n <- (qnorm(0.95)**2)*(sigma**2)*V.yp/(log(2)**2)
n <- ceiling(n)
prop.failing <- psev((log(4000) - mu)/sigma)
V.yp <- varianceFactorQuantile(0.05,prop.failing,"sev")
n <- (qnorm(0.95)**2)*(sigma**2)*V.yp/(log(2)**2)
n <- ceiling(n)
qnorm(0.95)
prop.failing <- psev((log(3000) - mu)/sigma)
V.yp <- varianceFactorQuantile(0.05,prop.failing,"sev")
R <- exp(qnorm(0.95)*sqrt((sigma**2)*V.yp/n))
R <- round(R,3)
